{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEBSCRAPING DE GENECARDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUPO 7:\n",
    " - Salvador Cama, Alejandro 20190310\n",
    " - Velasquez Gonzales, Pedro Daniel 20170382\n",
    " - Farfán Florián Erik David 20160229\n",
    " - Inoñan Sandoval, José Agustín  20190299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para realizar el webscraping\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los datos del archivo Excel\n",
    "datos=pd.read_excel(\"CHGenesOrdenadosConVecinos.xlsx\",engine=\"openpyxl\",skiprows=1,usecols=[0,1,2,3,4,5,6,7])\n",
    "# Imprimimos los datos extraídos\n",
    "datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una lista con los nombres abreviados de los genes \n",
    "lista_genes = datos['Gen Abrev'].values\n",
    "print(lista_genes)\n",
    "# print(len(lista_genes))   # son 212 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos los link`s correspondientes a cada gen y los almacenamos en una lista.\n",
    "links=[]\n",
    "# recorremos la lista de genes para crear los urls necesarios\n",
    "for i in lista_genes:\n",
    "    url=\"https://www.genecards.org/cgi-bin/carddisp.pl?gene=\"+i+\"#expression\"\n",
    "    links.append(url)  #llenamos la lista con cada url\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos webdriver para controlar chrome\n",
    "driver=webdriver.Chrome(executable_path=\"C:/Users/RYZEN 5-2600/Documents/chromedriver.exe\")\n",
    "#CREAMOS LISTA VACIA html\n",
    "html=[]\n",
    "#Recorremos la lista de links de los genes\n",
    "for link in links_genes:\n",
    "    driver.get(link) #abre cada link\n",
    "    try:            #evita errores\n",
    "        element = driver.find_element_by_id(\"expressionImage\") #recurre al motor de busqueda\n",
    "        soup = BeautifulSoup(driver.page_source,features=\"html.parser\") #crea la sopa\n",
    "        while(soup.find(\"area\")==None): #mientras area sea None, llenamos la lista html\n",
    "            driver.get(link)\n",
    "            soup = BeautifulSoup(driver.page_source,features=\"html.parser\")\n",
    "        html.append(soup)\n",
    "    except:\n",
    "        html.append(None)\n",
    "        continue\n",
    "driver.quit() #cerremos el motor de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea una lista vacia llamada info\n",
    "info = [] \n",
    "for i in html:\n",
    "    L=[]  # lista vacía para almacenar los datos solicitados de los html`s\n",
    "    if i == None:   # si no encuentra el html lo almacena como None\n",
    "        L.append(None)\n",
    "    else:  \n",
    "        soup=i  # de lo contrario, si encuentra un html con informacion se comienza a agragar los datos solicitados utilizando BeautifulSoup\n",
    "        L.append(soup.find('span',{'class':'gc-category'}).text)\n",
    "        L.append(soup.find_all('span',{'class':'aliasMainName'})[1].text)\n",
    "        lista=soup.find_all('area',{'title':re.compile('.Breast.')})\n",
    "        L.append(lista[0]['title'].split(',')[0]+', '+lista[3]['title'].split(',')[0])\n",
    "        L.append(lista[1]['title'].split(',')[0])\n",
    "        L.append(lista[2]['title'].split(',')[0])\n",
    "    info.append(L)\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el data frame \"info2\" con las columnas que poseen la informacion requerida\n",
    "info2 = pd.DataFrame(info , columns=['Category','Name of the gene','RNASeq','Microarray','SAGE'])\n",
    "# Creamos la primera columna con los nombres de los genes\n",
    "columna1=datos['Gen Abrev']\n",
    "# Creamos las columnas de categoria y nombre\n",
    "columna2=info2.iloc[:,[0,1]]\n",
    "# Creamos las columnas con los datos extraidos del excel \n",
    "columna3=datos[['Inicio','Final']]\n",
    "# Creamos las columnas con la informacion del BREAST\n",
    "columna4=info2.iloc[:,2:5]\n",
    "# Concatenamos las columnas \n",
    "EXCEL=pd.concat([columna1,columna2,columna3,columna4],axis=1)\n",
    "# Llenamos con NULL los casilleros vacios\n",
    "EXCEL=EXCEL.fillna(value='Null')\n",
    "# Imprimimos las primeros 20 filas\n",
    "EXCEL.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIBLIOGRAFIA:**\n",
    " - https://github.com/prbehere93/Genecards_Webscraping/blob/main/Genecards_scraper.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
